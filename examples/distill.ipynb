{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aVD7rBbjDzEy",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!curl https://colab.chainer.org/install | sh -\n",
    "\n",
    "!apt-get install graphviz\n",
    "!pip install 'chaineripy'\n",
    "!pip install 'chainercv'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from functools import partial\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "from chainer.links.caffe.caffe_function import CaffeFunction\n",
    "from chainer.serializers import npz\n",
    "from chainer.datasets import cifar, split_dataset_random, TransformDataset\n",
    "from chainer import links as L\n",
    "from chainer import initializers, serializers\n",
    "from google.colab import drive\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "base_dir = './drive/My Drive/study'\n",
    "sys.path.append(base_dir)\n",
    "drive.mount('/content/drive')\n",
    "caffemodel = CaffeFunction(base_dir + '/squeezenet/caffe/squeezenet_v1.1.caffemodel')\n",
    "npz.save_npz('squeezenet_v1_1.npz', caffemodel, compression=False)\n",
    "caffemodel = CaffeFunction(base_dir + '/squeezenet/caffe/squeezeNet_residual.caffemodel')\n",
    "npz.save_npz('squeeze_resnet.npz', caffemodel, compression=False)\n",
    "\n",
    "from resnet.networks.resnet101 import ResNet101\n",
    "from resnet.networks.resnet152 import ResNet152\n",
    "from squeezenet.networks.squeezenet import SqueezeNet\n",
    "from squeezenet.networks.squeezenet_bn import SqueezeNetBN\n",
    "from squeezenet.networks.squeeze_resnet import SqueezeResNet\n",
    "from squeezenet.networks.squeeze_pre_resnet import SqueezePreResNet\n",
    "from distill.knowledge_distill import DistillClassifier, softmax_cross_entropy_softlabel\n",
    "from distill.utils import save_softlabels, generate_softlabel\n",
    "from execute import run_train\n",
    "from transform import transform, transform_with_softlabel\n",
    "\n",
    "# Dataset setup\n",
    "train_val, test = cifar.get_cifar10(scale=255.)\n",
    "train_size      = int(len(train_val) * 0.9)\n",
    "train, valid    = split_dataset_random(train_val, train_size, seed=0)\n",
    "mean = np.mean([x for x, _ in train], axis=(0, 2, 3))\n",
    "std  = np.std([x for x, _ in train], axis=(0, 2, 3))\n",
    "\n",
    "params = json.load(open(base_dir + '/params.json', \"r\"))\n",
    "distill_params = json.load(open(base_dir + '/distill/distill_params.json', \"r\"))\n",
    "train_soft_path = base_dir + '/soft_labels.npy'\n",
    "valid_soft_path = base_dir + '/soft_labels_valid.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgvPR3PEQerm",
    "colab_type": "text"
   },
   "source": [
    "## Generating soft labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mSIhgVTpMRIl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "teacher = ResNet101(10, pretrained_model=None)\n",
    "serializers.load_npz(\n",
    "    'drive/My Drive/study/result/snapshot_epoch-33',\n",
    "    teacher, path='updater/model:main/predictor/')\n",
    "teacher.to_gpu()\n",
    "fun_generate_soft = partial(generate_softlabel, model=teacher, mean=mean, std=std, **params)\n",
    "\n",
    "if not os.path.exists(train_soft_path):\n",
    "    save_softlabels(train, fun_generate_soft, base_dir + '/soft_labels')\n",
    "if not os.path.exists(valid_soft_path):\n",
    "    save_softlabels(valid, fun_generate_soft, base_dir + '/soft_labels_valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krHvLEPDUQup",
    "colab_type": "text"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code",
    "id": "T_t5FFYne4IP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760.0
    },
    "outputId": "0595bf30-a98b-47ab-946f-10f0b757d304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  lr          elapsed_time\n",
      "\u001b[J1           24.8915     0.139138       23.1447        0.193359           0.001       175.15        \n",
      "\u001b[J2           21.9046     0.2504         18.4107        0.345508           0.001       351.456       \n",
      "\u001b[J3           18.8533     0.350739       15.8025        0.45625            0.001       527.89        \n",
      "\u001b[J4           15.4474     0.486728       12.8443        0.574023           0.001       705.171       \n",
      "\u001b[J5           12.3497     0.609731       10.6911        0.674609           0.001       882.474       \n",
      "\u001b[J6           9.55761     0.711648       7.22654        0.786914           0.001       1060.41       \n",
      "\u001b[J7           7.53711     0.780783       5.84999        0.838086           0.001       1238.89       \n",
      "\u001b[J8           6.56787     0.81068        5.3367         0.857813           0.001       1416.59       \n",
      "\u001b[J9           6.03087     0.826682       4.80809        0.874219           0.001       1594.38       \n",
      "\u001b[J10          5.63947     0.839655       4.73462        0.87793            0.001       1771.93       \n",
      "\u001b[J11          5.3935      0.84941        4.80488        0.875781           0.001       1949.96       \n",
      "\u001b[J12          5.08225     0.860199       5.04907        0.867188           0.001       2127.57       \n",
      "\u001b[J13          4.84816     0.866744       4.50747        0.885352           0.001       2306.11       \n",
      "\u001b[J14          4.70001     0.870905       4.53213        0.880859           0.001       2483.35       \n",
      "\u001b[J15          4.52513     0.87642        4.17778        0.892383           0.001       2661.23       \n",
      "\u001b[J16          4.29551     0.885305       4.58209        0.883594           0.001       2838.6        \n",
      "\u001b[J17          4.23175     0.887873       4.82748        0.877539           0.001       3016.44       \n",
      "\u001b[J18          4.12478     0.890869       3.98822        0.904688           0.001       3193.93       \n",
      "\u001b[J19          4.07242     0.892094       4.16273        0.90293            0.001       3372.04       \n",
      "\u001b[J20          3.89071     0.897661       3.95735        0.898242           0.001       3549.83       \n",
      "\u001b[J21          3.07484     0.927128       3.51659        0.921094           0.0001      3726.96       \n",
      "\u001b[J22          2.81014     0.935147       3.48274        0.922461           0.0001      3904.51       \n",
      "\u001b[J23          2.76998     0.936676       3.52954        0.920898           0.0001      4081.6        \n",
      "\u001b[J24          2.66723     0.940763       3.55376        0.921289           0.0001      4258.92       \n",
      "\u001b[J25          2.67948     0.940186       3.44001        0.923828           0.0001      4437.08       \n",
      "\u001b[J26          2.65122     0.94075        3.47574        0.924805           0.0001      4613.42       \n",
      "\u001b[J27          2.65529     0.942006       3.47024        0.924805           0.0001      4790.76       \n",
      "\u001b[J28          2.60692     0.943955       3.50689        0.923828           0.0001      4967.6        \n",
      "\u001b[J29          2.60372     0.943315       3.43339        0.921875           0.0001      5144.91       \n",
      "\u001b[J30          2.55036     0.946114       3.46276        0.926562           0.0001      5321.44       \n",
      "\u001b[J31          2.499       0.946311       3.41211        0.928516           1e-05       5499.28       \n",
      "\u001b[J32          2.49302     0.94667        3.40587        0.928711           1e-05       5675.78       \n",
      "\u001b[J33          2.45558     0.947976       3.41418        0.92832            1e-05       5852.98       \n",
      "\u001b[J34          2.45421     0.947266       3.41518        0.927539           1e-05       6030          \n",
      "\u001b[J35          2.43095     0.948918       3.42181        0.92793            1e-05       6206.64       \n",
      "\u001b[J36          2.46895     0.947687       3.40467        0.926953           1e-05       6383.47       \n",
      "\u001b[J37          2.43163     0.94805        3.41732        0.928711           1e-05       6560.57       \n",
      "\u001b[J38          2.46592     0.948331       3.40341        0.927539           1e-05       6737.5        \n",
      "\u001b[J39          2.45656     0.948429       3.41269        0.926172           1e-05       6913.78       \n",
      "\u001b[J40          2.45832     0.948531       3.41466        0.927539           1e-05       7090.64       \n"
     ]
    }
   ],
   "source": [
    "from chainer.dataset.convert import concat_examples\n",
    "from chainer.datasets import tuple_dataset\n",
    "\n",
    "img_t, lab_t = concat_examples(train)\n",
    "soft_labels_t = np.load(base_dir + '/soft_labels.npy')\n",
    "train_soft = tuple_dataset.TupleDataset(img_t, soft_labels_t, lab_t)\n",
    "\n",
    "img_v, lab_v = concat_examples(valid)\n",
    "soft_labels_v = np.load(base_dir + '/soft_labels_valid.npy')\n",
    "valid_soft = tuple_dataset.TupleDataset(img_v, soft_labels_v, lab_v)\n",
    "\n",
    "# DATA AUGMENTATION\n",
    "transform_train = partial(transform_with_softlabel, mean=mean, std=std, train=True, **params)\n",
    "transform_valid = partial(transform_with_softlabel, mean=mean, std=std, train=False, **params)\n",
    "processed_train = TransformDataset(train_soft, transform_train)\n",
    "processed_valid = TransformDataset(valid_soft, transform_valid)\n",
    "\n",
    "# MODEL DEFINITION AND FINETUNING\n",
    "student = SqueezeNet(10, init_param=initializers.HeNormal())\n",
    "serializers.load_npz(\n",
    "    'drive/My Drive/study/result/snapshot_epoch-40',\n",
    "    student, path='updater/model:main/predictor/')\n",
    "\n",
    "# DISTILL\n",
    "alpha = distill_params['alpha']\n",
    "t = distill_params['temperature']\n",
    "net = DistillClassifier(student, lossfun_soft=softmax_cross_entropy_softlabel, alpha=alpha, t=t)\n",
    "\n",
    "\n",
    "# RUN!\n",
    "params['save_trainer_interval'] = 6\n",
    "params['batchsize']     = 128\n",
    "params['result_dir']    = 'drive/My Drive/study/result'\n",
    "run_train(processed_train, processed_valid, net, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "uwI2ucPxgBIq",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "version": "0.3.2",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
